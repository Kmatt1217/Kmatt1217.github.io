---
title: SRGAN
categories:
 - 논문 구현
tags:
 - GAN
 - DeepLearning
 - Generative model
toc: true
toc_sticky: true
author_profile: true
sidebar:
  nav: "categories"
---

참고 논문: [SRGAN.pdf](https://github.com/Kmatt1217/Kmatt1217.github.io/files/11175852/SRGAN.pdf)

# 1. Introduction 

![스크린샷 2023-04-07 12-32-51](https://user-images.githubusercontent.com/129755780/230535559-9f1d7a0a-22e7-4145-9cda-1c110d93ae4c.png)

SGRAN을 통해 4 X Scaling한 이미지와 원본 이미지의 비교

이 논문은 저해상도(LR) 이미지를 고해상도(HR) 이미지로 업스케일링하는 초고해상도(SR) 생성적 적대 신경망(SRGAN)을 제안한다. 
기존 방법과 달리, VGG 네트워크의 High Level 특징 맵을 사용하여 새로운 손실, perceptual loss을 정의하고, HR 이미지와 구별하기 어려운 해결책을 제시하는 판별자(discriminator)를 결합한다. 
4배 upscaling factor로 초고해상도 이미지를 생성한 예시가 제시되었다.

## 1.1 Related work

### 1.1.1 Image super-resolution

Image super-resolution은 저해상도 이미지(low-resolution image)를 고해상도 이미지(high-resolution image)로 변환하는 기술이다. 
이러한 문제를 해결하기 위한 다양한 방법이 제안되었는데, 이 논문에서는 단일 이미지 초해상도(single image super-resolution, SISR)에 초점을 맞추고 있다.

SISR 문제를 해결하기 위한 예측 기반 방법은 linear, bicubic 등의 필터링 기술을 이용하는 것이다. 
하지만 이러한 방법은 문제를 과도하게 단순화하고 심하게 smooth한 텍스처의 이미지를 생성해 원본의 특징을 제대로 표현하지 못하는 단점이 있다.

좀 더 강력한 방법은 저해상도 이미지와 고해상도 이미지 간의 복잡한 mapping을 정의하는 것이다. 
이를 위해 예시 쌍을 기반으로한 방법과 이를 학습시키는 방법이 있다. 
이 중에서도 자기 유사성(self-similarity) 개념을 활용하는 방법과 이를 발전시킨 방법이 제안되었다. 
또한 전체 이미지를 처리하는 Convolutional sparse coding 알고리즘과 Neighborhood embedding 방법도 제안되었다.

최근에는 합성곱 신경망(CNN)을 이용한 초해상도 알고리즘이 많이 발전하고 있다. 
이 방법들은 Sparse represntation 알고리즘을 네트워크 구조에 인코딩하는 것이나, 완전 합성곱 신경망(fully convolutional network)을 이용하는 것과
심층 재귀형 신경망(deeply-recursive convolutional network)을 사용하는 것 등 다양한 방법으로 구현된다. 
특히, Johnson et al. 및 Bruna et al.의 작업은 인지적 유사성(perceptual similarity)에 가까운 손실 함수를 사용하여 시각적으로 더 진실된 고해상도 이미지를 복원한다.

### 1.1.2 Design of convolutional neural networks

컴퓨터 비전 분야에서 최신 기술은 Krizhevsky의 연구로부터 시작되어 특별히 설계된 CNN 아키텍처에 의해 설정된다. 

Deeper Network의 아키텍처는 매우 큰 복잡성을 가진 Mapping 함수를 모델링할 수 있기 때문에 네트워크의 정확도를 크게 높일 수 있지만, 이 때문에 학습이 어려울 수 있다.

따라서 일반적으로 batch-normalization [32]을 사용하여 내부 공변량 이동을 균형시키는 것이 좋습니다. 

또한 residual blocks과 skip-connections이라는 개념을 도입하여 Deepp Convolutional Neural Network의 학습을 용이하게 할 수 있다. 

이러한 모델의 설계는 SISR에서도 성능을 향상시킨다. 특히, upscaling filters를 학습시키는 것이 정확도와 속도면에서 이점을 가져다준다.

Dong et al. 에서는 bicubic interpolation을 사용하여 upscale하는 반면, 최근에는 upscaling filters를 직접 학습시키는 것이 성능을 높일 수 있다는 것이 입증되다.

### 1.1.3 Loss functions

픽셀 단위의 손실 함수는 텍스처와 같은 detail한 정보를 복원하는 데 어려울 수 있다.

MSE를 최소화하는 것은 가능한 Solution(가능한 이미지들의 벡터 공간)을 픽셀 단위로 평균화하여 지나치게 부드러운 복원 결과를 만들어내고, 따라서 시각적인 이미지의 quatlity가 떨어진다. 

이러한 문제를 해결하기 위해 GAN과 같은 새로운 기술이 도입되어 사용되었다.

VGG와 같은 pretrained 신경망에서 추출된 feature map을 사용하여 유클리드 거리 기반의 손실 함수를 제안하였고, 이는 SR 및 style transfer에 대한 향상된 시각적인 결과를 도출하는 데 효과적이다.

이러한 방법들은 MSE 손실 함수와 같은 저수준 픽셀 단위 오류 측정 방식보다 시각적으로 더 나은 결과를 도출할 수 있다.

## 1.2 Contribution

이 논문은 이미지 super-resolution(SISR)에 대한 새로운 접근 방법을 제안한다. 

GAN을 활용하여 높은 quality의 이미지를 생성하기 위해 매우 깊은 ResNet 구조를 설계하였다. 

이러한 구조에서는 MSE 기반의 content 손실 대신, VGG 네트워크의 feature map을 기반으로 한 손실 함수를 사용하여 더욱 인간의 시각 체계에 가까운 결과물을 생성할 수 있게했다.

이러한 아이디어를 SRGAN이라는 이름의 GAN-based 네트워크에 적용하였다.

# 2. Method

SISR은 원본 이미지의 저해상도 버전 이미지 $I^{L R}$로부터 초고해상도 이미지 $I^{S R}$을 추정하는 것이다.
훈련 중에는 고해상도 이미지만 사용 가능하며, $I^{L R}$은 Gaussian 필터를 적용한 후 $r$배 down sampling 결과다.
여기서 $r$은 다운샘플링 factor이며, $C$는 이미지의 채널 수 이다.

이를 위해 생성 함수 $G$를 훈련시켜야 한다. $G$는 파라미터 $θ_G$를 가진 feed forward CNN으로, $θ_G$ = ${W1:L ; b1:L }$는 $L$층 layer의 가중치와 편향을 나타내며, 

SR의 손실 함수 $l^{S H}$을 최적화하여 얻는다. N개의 훈련 이미지 중 n번째에 해당하는 $I_{n}^{L R}&이 주어지면, 다음과 같은 최적화 문제를 풀 수 있다.

$$
\hat{\theta}_{G}=\arg \min _{\theta_{G}} \frac{1}{N} \sum_{n=1}^{N} l^{S R}\left(G_{\theta_{G}}\left(I_{n}^{L R}\right), I_{n}^{H R}\right)
$$

이 논문에서는 복원된 SR 이미지의 다양한 특성을 모델링하는 여러 손실 함수들의 weighted sum으로 구성된 SR 특정 손실 함수 $l^{S H}$을 구체적으로 설계한다.

## 2.1 Adversarial network architecture


SRGAN은 기본적으로 GAN을 기반으로 한다.
이 모델은 고해상도의 이미지를 생성하는데 사용된다.
이를 위해 SRGAN은 생성자(generator)와 판별자(discriminator)라는 두 개의 신경망을 사용한다.

Generator는 저해상도 이미지를 입력으로 받아, 이를 고해상도 이미지로 변환하는 작업을 수행한다.

![스크린샷 2023-04-07 13-21-34](https://user-images.githubusercontent.com/129755780/230540265-154e6100-cf93-4baa-ae42-f2e3aad3fb35.png)

Generator는 매우 깊은(residual) 구조를 가지고 있으며, Convolution 블록의 layout을 따른다.

이 블록은 3x3 사이즈의 kernel을 가지는 convolution 레이어 2개, batch normalization 레이어, 그리고 PReLU(Parametric ReLU) 활성화 함수를 포함한다.

입력 이미지의 해상도를 높이기 위해 훈련된 sub-pixel 컨볼루션 레이어 2개가 추가로 사용다.

Discriminator는 Generator가 생성한 SR 이미지와 HR 이미지를 입력으로 받아, 이를 구분하는 작업을 수행한다.

Discriminator는 8개의 Convolution 레이어를 가지고 있으며, LeakyReLU 활성화 함수를 가지고 있다. 단, max-pooling이 없는 구조를 따른다. 

Discriminator는 이진 분류(binary classification) 문제를 해결하기 위해 sigmoid 활성화 함수를 마지막 층에 사용한다.

SRGAN의 학습 방법은 Generator와 Discriminator를 번갈아 가면서 훈련하는 GAN 기법을 사용합니다. 

이 방법은 Generator가 HR 이미지와 유사한 SR 이미지를 생성하도록 유도하며, Discriminator는 이를 판별하는 데에 사용한다. 

## 2.2 Perceptual loss function

SRGAN에서는 SR이미지와 원본 이미지 간의 차이를 측정하는 손실 함수가 중요하다.

일반적으로 SR 이미지와 원본 이미지의 차이를 계산하기 위해 MSE를 사용하는데 이 논문에서는 콘텐츠 손실($l^{S R}$)과 적대적 손실($l^{S R}$)을 가중합한 인지적 손실 함수를 사용합니다.

$$l^{SR}=l_{\mathrm{x}}^{SR}+10^{-3}l_{Gen}^{SR}$$

위 식에서 볼 수 있듯이, 인지적 손실 함수는 VGG 기반의 콘텐츠 손실과 적대적 손실의 가중합으로 이루어진다.

## 2.2.1 Content loss

픽셀 단위 손실 함수 대신 Perceptual 유사성에 더 가까운 손실 함수를 사용합니다. 19 layers의 VGG 네트워크의 ReLU 활성화 레이어를 기반으로 하는 VGG 손실을 정의한다.

$$
\begin{aligned}
l_{V G G / i . j}^{S R}=\frac{1}{W_{i, j} H_{i, j}} & \sum_{x=1}^{W_{i, j}} \sum_{y=1}^{H_{i, j}}\left(\phi_{i, j}\left(I^{H R}\right)_{x, y}\right. \\
& \left.-\phi_{i, j}\left(G_{\theta_{G}}\left(I^{L R}\right)\right)_{x, y}\right)^{2}
\end{aligned}
$$

여기서 $\phi_{i, j}$는 VGG19 네트워크 내에서 i 번째 max-pooling 레이어 이전의 j 번째 합성곱(활성화 후)으로부터 얻은 feature map을 나타내고 이를 고정값으로 간주한다.

그런 다음 재구성된 이미지 $G_{\theta_{G}}\left(I^{L R}\right)$ 의 특징 표현과 참조 이미지 $I^{H R}$ 의 특징 표현 간의 유클리드 거리를 VGG 손실을 정의한다.

여기서 $W_{i, j}$와 $H_{i, j}$는 VGG 네트워크 내에서 해당 feature map의 dimension을 나타낸다.

### 2.2.2 Adversarial loss

기존 GAN의 손실 함수이다. 

$$
l_{G e n}^{S R}=\sum_{n=1}^{N}-\log D_{\theta_{D}}\left(G_{\theta_{G}}\left(I^{L R}\right)\right)
$$

Generative loss  $l_{G e n}^{S R}$ 은 모든 훈련 샘플에 대한 Discriminator $D_{\theta_{D}}\left(G_{\theta_{G}}\left(I^{L R}\right)\right)$의 확률에 기반하여 정의된다.

여기서 $D_{\theta_{D}}\left(G_{\theta_{G}}\left(I^{L R}\right)\right)$은 재구성된 이미지 $G_{\theta_{G}}\left(I^{L R}\right)$가 자연스러운 HR 이미지임을 나타내는 확률을 나타낸다. 

$\log \left[1-D_{\theta_{D}}\left(G_{\theta_{G}}\left(I^{L R}\right)\right)\right]$로 Graident계산 시 초기에 학습 속도가 느린 점이 있어서, $-\log D_{\theta_{D}}\left(G_{\theta_{G}}\left(I^{L R}\right)\right)$를 대신 최소화한다.

# 코드

## Training details and paramters

bicubic 커널 사용, Downsapling factor: r=4

VGG feature map layer: 19 

Optimizer: Adam(학습률 10^-4)

## Setup & Utils

<script src="https://gist.github.com/Kmatt1217/ea2fa528cd8323999d86e01dc28ef6a9.js"></script>

utils.py 로 저장하였따.



## Generator

<script src="https://gist.github.com/Kmatt1217/3c4439dd73739525bc25b598818d6899.js"></script>

## Discriminator

<script src="https://gist.github.com/Kmatt1217/1e2af953f2b20ee42ebdde3e83822fb5.js"></script>

## VGG_featrue_extractor

<script src="https://gist.github.com/Kmatt1217/5f205d8130c8fe3937dba7cf828b5465.js"></script>

## Main

### Loading Modules
<script src="https://gist.github.com/Kmatt1217/ea7f3a204aa917d44fbe23dcf1f2b434.js"></script>

필요한 모듈 loading

### Device-Agnostic code + Hyperparamters Setting
<script src="https://gist.github.com/Kmatt1217/c5bf5765eedd5add036845926624e901.js"></script>

GPU 사용을 위한 device-agnostic code

하이퍼파라미터:
 1. IMAGE_CHANNEL : 컬러 이미지 'RGB' 3개의 채널을 가지고 있음.
 2. HIDDEN_DIM : 2.1의 이미지에서 Discriminator와 Generator의 Convolution layer의 Out_channel
 3. NUM_EPOCHS : 5
 4. hr_height : 고해상도 이미지의 높이
 5. hr_width : 고해상도 이미지의 너비
 6. hr_shape : 고해상도 이미지의 높이x너비
 7. BATCH_SIZE : 미니 배치 크기, 16으로 하니 안돌아가서 4로 하였다...
 8. LEARNING_RATE : optimizer(Adam)에 쓰일 학습률

### Preparing Datasets

<script src="https://gist.github.com/Kmatt1217/4895b14e38f96d3b87467cd2fbd6e05f.js"></script>

celeba dataset 사용. http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html

### Define Generator, Discriminator, feature_extarctor(VGG)

<script src="https://gist.github.com/Kmatt1217/454ea2e8f74b707d242e6647a9fba3b4.js"></script>

Generator의 scale_factor는 논문에 나와있듯이 2로 해주자. (총 Upscaling이 2번일어나 저해상도 이미지의 크기가 후에 4배가 됨)

`feature_extractor.eval()` 무조건 해줘야 한다.
VGG의 layer들을 특성 추출기로 사용하여 content loss를 계산하는데 쓰이므로, VGG 네트워크의 paramter들도 학습되어 바뀌면 곤란하기 때문.

### Optimizer & Criterion

<script src="https://gist.github.com/Kmatt1217/4153fd0a32239ec48c92aa5bbd0613bb.js"></script>

논문에 따라서, optimizer로 Adam을 사용하고, beta1 = 0.5로 설정.

GAN의 손실 함수는 MSE, Content 손실함수는 L1Loss

### TRAIN

<script src="https://gist.github.com/Kmatt1217/ecb41f1e6e370abc8bcd21d1d27d34f9.js"></script>

